# lab2
## Теоретичні питання

### 1. Що таке власне значення і власний вектор матриці? Як вони обчислюються?

Власне значення (λ) та власний вектор (v) матриці \( A \) визначаються як рішення рівняння:
A⋅v=λ⋅v

Для обчислення власних значень потрібно вирішити рівняння:
det(A−λI)=0
де (I) — одинична матриця того ж розміру, що і (A). Знайдені корені цього рівняння є власними значеннями матриці (A).

Після обчислення власних значень, для знаходження відповідних власних векторів потрібно підставити кожне власне значення (λ) в рівняння:
(A−λI)*v=0
і вирішити систему рівнянь відносно (v).

### 2. Які властивості мають власні вектори симетричних матриць?

Власні вектори симетричних матриць мають такі властивості:
- Власні вектори, що відповідають різним власним значенням, є ортогональними.
- Симетричні матриці мають тільки дійсні власні значення.
- Всі власні вектори симетричних матриць можуть бути обрані ортонормованими, тобто вони можуть бути нормалізовані так, що їх довжина дорівнює одиниці, і вони перпендикулярні один до одного.

### 3. Які можуть бути недоліки використання PCA, і які стратегії можуть використовуватися для подолання цих недоліків?

#### Недоліки використання PCA:
- **Втрата інформації:** Якщо обирається занадто мала кількість компонентів, можна втратити чіткість зображення.
- **Лінійність:** PCA передбачає лінійність даних і може бути неефективним для нелінійних структур.
- **Чутливість до масштабу:** Якщо дані не нормалізовані, компоненти з більшими масштабами можуть переважати над іншими.
- **Інтерпретованість:** Нові компоненти можуть бути важко інтерпретувати в контексті вихідних даних.

#### Стратегії для подолання цих недоліків:
- **Попереднє масштабування даних:** Нормалізація або стандартизація даних перед застосуванням PCA.
- **Використання нелінійних варіантів:** Використання нелінійних методів, таких як Kernel PCA, для обробки нелінійних даних.
- **Оптимальний вибір компонентів:** Використання методів, таких як крива відсічення (elbow curve) або аналіз кумулятивної дисперсії, для визначення оптимальної кількості компонентів.
- **Комбінація з іншими методами:** Використання PCA в поєднанні з іншими методами зменшення розмірності або кластеризації.

### 4. Які переваги має діагоналізація матриці в криптографії? Як вона застосовується для шифрування та дешифрування повідомлень?

#### Переваги діагоналізації матриці в криптографії:
- **Спрощення обчислень:** Діагоналізація перетворює складні матричні операції на простіші, оскільки діагональні матриці легше інвертувати та використовувати в обчисленнях.
- **Ефективність:** Діагоналізація дозволяє розкласти матрицю на власні вектори та власні значення, що спрощує операції множення та обернення.

#### Застосування для шифрування та дешифрування:
- **Шифрування:** Повідомлення кодується шляхом множення його на матрицю ключа. Якщо матриця ключа діагоналізується, то її можна розкласти на добуток матриці власних векторів і діагональної матриці власних значень.
- **Дешифрування:** Розшифрування виконується за допомогою оберненої матриці ключа, яка легко обчислюється, якщо матриця діагоналізується. Це дозволяє використовувати обернені власні значення і власні вектори для відновлення оригінального повідомлення.
